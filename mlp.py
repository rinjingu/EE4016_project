# -*- coding: utf-8 -*-
"""mlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QqqXi152GCILR2lfJ0LUBZsn9RlZnZ8I
"""

import torch
import torch.nn as nn
from torch.optim import Adam
from torch.optim import SGD
from torch.utils.data import Dataset, DataLoader
import json
import os
from sklearn.preprocessing import StandardScaler
import numpy as np

# Define the MLP model
class MLP(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x

# Load JSON data from a file
cwd = os.getcwd() # Set current working directory
preset_data = [] #add read size
with open(os.path.join(cwd, 'data.json'), 'r') as f:
    for line in f:
        preset_data.append(json.loads(line))

class item_based_dataset(Dataset):
    def __init__(self, preset_data):
        self.preset_data = preset_data

    def __getitem__(self, index):
        try:
            asin = self.preset_data[index]['asin']
            price_mean = float(self.preset_data[index]['price'][0].split('.')[0]) if self.preset_data[index]['price'][0] else -1
            price_diff = float(self.preset_data[index]['price'][1].split('.')[0]) if self.preset_data[index]['price'][1] else -1
            avg_rating = float(self.preset_data[index]['avg_rating']) if self.preset_data[index]['avg_rating'] else -1
            rank = float(self.preset_data[index]['rank']) if self.preset_data[index]['rank'] else -1
            brand = float(self.preset_data[index]['brand']) if self.preset_data[index]['brand'] else -1
            category = self.preset_data[index]['category'] or [-1, -1]
            category_a, category_b = (category + [-1, -1])[:2]
            activeness = float(self.preset_data[index]['activeness']) if self.preset_data[index]['activeness'] else -1
            packed_data = [price_mean, price_diff, rank, brand, category_a, category_b, activeness]
            trainset = torch.tensor(packed_data)  # convert to tensor
            Verify_ans = torch.tensor([avg_rating], dtype=torch.float)
            return trainset, Verify_ans
        except KeyError as e:
            print(f"KeyError: {e} is not found in the data at index {index}")
        except Exception as e:
            print(f"An error occurred: {e}")

    def __len__(self):
        return len(self.preset_data)

# Define hyperparameters
input_size = 7  # Dimension of input features
hidden_size = 128  # Number of neurons in the hidden layer
output_size = 1  # Dimension of output (predicted rating)

# Instantiate the model
model = MLP(input_size, hidden_size, output_size)

# Define loss function and optimizer
criterion = nn.MSELoss()
optimizer = SGD(model.parameters(), lr=0.001)

# Instantiate the dataset and dataloader
dataset = item_based_dataset(preset_data)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

num_epochs = 30
for epoch in range(num_epochs):
    running_loss = 0.0
    for inputs, targets in dataloader:
        optimizer.zero_grad()
        outputs = model(inputs.float())
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * inputs.size(0)  # Multiply by batch size

    # Calculate average loss for the epoch
    epoch_loss = running_loss / len(dataloader.dataset)

    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {epoch_loss:.4f}')